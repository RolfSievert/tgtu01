
Set spell check with “:setlocal spell spelllang=[en/sv]”  — title: Förberedelse inför seminarie 1 date:

<h2 id="output-pdf">output: pdf</h2>
<p><em>1. Hur bör autonoma fordon programmeras att agera i situationer som behandlas i artikeln (dvs. där fordonet måste “välja” mellan att köra av vägen eller att köra på medtrafikanter)? Vad för etiska principer kan vara relevanta att utgå ifrån? Motivera ditt svar.</em></p>
<blockquote>
<p>Fler kommer antagligen att köpa bilen om den skyddar passagerarna, och även då skulle dödssiffrorna minska. Så till en början säga att de skyddar passagerarna (om inte det är ett stort antal som offras, där majoriteten av människorna är överens, bestäms statistiskt alltså).</p>
</blockquote>
<blockquote>
<p>När autonoma fordon introducerats till samhället ordentligt kan regeringen börja reglera att fordonen ska utgöra så lite skada som möjligt. Vilket är bäst i praktiken om man vill rädda antal, vilket de flesta var överens om i artikeln.</p>
</blockquote>
<p><em>2. Vem eller vilka bär det moraliska ansvaret om/när skada med autonoma farkoster inträffar? Vilka typer av ansvar kan det vara relevant att tillskriva olika inblandade aktörer. Motivera ditt svar.</em></p>
<blockquote>
<p>Tillverkaren av fordonen som måste möta vissa förväntningar. Regeringen som sätter förväntningarna. Eventuellt ägaren av fordonet som har köpt en bil med en viss algoritm.</p>
</blockquote>
<p><em>3. Hur autonoma bör system som rör människors säkerhet vara?</em></p>
<blockquote>
<p>Jag tror det ska vara så pass autonomt att det finns en förfrågan (inte tar ifrån frihet från människan) och att den utilitarianistiska konsekvensen är större än innan. Kan motivera detta med universal-metoden.</p>
</blockquote>
<p><em>4. I vilken utsträckning, om alls, kan autonoma system alls tillskrivas moraliskt ansvar? Finns det situationer där det kan vara rimligt att tillskriva autonoma system ansvar?</em></p>
<blockquote>
<p>Teoretiskt om man anser att ett system har ett medvetande och kan agera fritt, för då har systemet valt att göra något (direkt opåverkat av andra). Svårt dock för när har ett ting ett medvetande?</p>
</blockquote>
<p><em>5. Det brukar hävdas att ingenjörer bör bereda sig på “worst case-scenarier” när de utvecklar teknik/tekniska system. Är detta ett rimligt krav gällande programmerare och programmering? Hur skulle ett worst case-scenario kunna se ut när det gäller programmeringen av t.ex. självstyrande bilar?</em></p>
<p>“Worst case” vore att bilen skulle ha större förödande konsekvenser. Kan också argumenteras för med universal-metoden. Kan också vara svårt att förutse och tänka på alla möjliga scenarion då misstag görs. Jag tycker därför att det är företaget som ska ansvara för konsekvenserna (då företaget har begärt produkten av utvecklaren), och att utvecklaren inte medvetet gör något som kan användas på ett dåligt sätt.</p>
